{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from nice_funcs.indicators import CreateRandomPrtf,EWMA,MACD,RSI,NormalizeWindow\n",
    "\n",
    "\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box\n",
    "import gymnasium\n",
    "\n",
    "from ddpg_tf2 import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_diario = './assets/1d/'\n",
    "ativos = os.listdir(path_diario)\n",
    "\n",
    "ativosOHLC = {}\n",
    "for ativo in ativos:\n",
    "    ativosOHLC[ativo.replace('.xlsx','')] = \\\n",
    "        pd.read_excel(os.path.join(path_diario,ativo),index_col=0)\n",
    "    \n",
    "\n",
    "close_prices = {}\n",
    "for k in ativosOHLC.keys():\n",
    "  close_prices[k] = ativosOHLC[k].Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fechamento = pd.DataFrame(close_prices)\n",
    "macd = df_fechamento.apply(lambda row: MACD(row)[0]).dropna()\n",
    "rsi = df_fechamento.apply(lambda row: RSI(row)).dropna()\n",
    "ewma_diff = df_fechamento.apply(lambda row: EWMA(row,20) - EWMA(row,5)).dropna()\n",
    "normalized_fech = df_fechamento.apply(lambda row: NormalizeWindow(row)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetIndex(*args):\n",
    "  indicators = [*args]\n",
    "  index_init = set(indicators[0].index)\n",
    "  for ind_ in indicators:\n",
    "    index_init = index_init & set(ind_.index)\n",
    "  \n",
    "  idx_date = min(index_init)\n",
    "  new_index_indicators = []\n",
    "  for ind_ in indicators:\n",
    "    new_index_indicators.append(ind_[idx_date:])\n",
    "  return new_index_indicators\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_fechamento = pd.DataFrame(close_prices)\n",
    "macd = df_fechamento.apply(lambda row: MACD(row)[0]).dropna()\n",
    "rsi = df_fechamento.apply(lambda row: RSI(row)).dropna()\n",
    "ewma_diff = df_fechamento.apply(lambda row: EWMA(row,20) - EWMA(row,5)).dropna()\n",
    "normalized_fech = df_fechamento.apply(lambda row: NormalizeWindow(row)).dropna()\n",
    "\n",
    "df_fechamento,normalized_fech,macd,rsi,ewma_diff =  GetIndex(df_fechamento,normalized_fech, macd, rsi, ewma_diff)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from stable_baselines3.common import env_checker\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "class TradingEnv(Env):\n",
    "    def __init__(self,fechamento,indicadores:list)->None:\n",
    "      super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "      self.fechamento = fechamento\n",
    "      self.idx_ = 0\n",
    "      self.step_ = 0\n",
    "      self.indicadores = indicadores\n",
    "      self.dinheiro_inicial = 1000\n",
    "      self.dinheiro_final = self.dinheiro_inicial\n",
    "      self.n_indicadores = len(self.indicadores)\n",
    "      self.n_ativos = len(self.fechamento.columns)\n",
    "      self.n_actions = self.n_ativos + 1\n",
    "      self.observation_space = Box(low=-np.inf,high=np.inf,shape = (self.n_indicadores,self.n_ativos),dtype='float32')\n",
    "      self.action_space = Box(low=0,high=1,shape= (self.n_actions,),dtype='float32')\n",
    "      self.done = False\n",
    "      self.truncated = False\n",
    "      self.max_steps = len(self.fechamento) -1\n",
    "\n",
    "    def CreateObs(self):\n",
    "      arr = []\n",
    "      idx_ = self.idx_\n",
    "      indicators = self.n_indicadores\n",
    "\n",
    "      for ind in self.indicadores:\n",
    "        arr.append(ind.iloc[idx_].values)\n",
    "      arr = np.array(arr)\n",
    "\n",
    "      return arr\n",
    "\n",
    "    def RewardFunc(self,precos,new_precos,action):\n",
    "      reward = sum(((new_precos - precos)/precos) * action) * self.dinheiro_final\n",
    "      return reward\n",
    "\n",
    "    def step(self,action):\n",
    "      info = {}\n",
    "      obs = self.CreateObs()\n",
    "      precos = self.fechamento.iloc[self.idx_]\n",
    "      self.step_ += 1\n",
    "      self.idx_ +=1\n",
    "\n",
    "      new_precos = self.fechamento.iloc[self.idx_]\n",
    "\n",
    "      reward = self.RewardFunc(precos,new_precos,action)\n",
    "\n",
    "      self.dinheiro_final -= reward\n",
    "\n",
    "      condicao_1 = (self.dinheiro_final/self.dinheiro_inicial)\n",
    "      condicao_2 = self.step_ >= self.max_steps\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "      if condicao_1 <= 0.1:\n",
    "        self.done = True\n",
    "\n",
    "      if condicao_2:\n",
    "        self.truncated = True\n",
    "     \n",
    "\n",
    "      return obs,reward,self.done,self.truncated,info\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "      self.step_ = 0\n",
    "      self.idx_ = 0\n",
    "      self.dinheiro_final = self.dinheiro_inicial\n",
    "      self.done = False\n",
    "      self.truncated = False\n",
    "      obs = self.CreateObs()\n",
    "        \n",
    "      return obs, {}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnv(df_fechamento,[normalized_fech,macd,rsi,ewma_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(input_dims = env.observation_space.shape[0],\\\n",
    "   env = env, n_actions =env.action_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48419625,  0.46516728, -1.1062176 , -0.6484952 ,  0.76721764,\n",
       "         0.7588199 ],\n",
       "       [-0.12108716, -2.5570064 ,  0.18738624,  0.36589372,  1.7179866 ,\n",
       "        -1.809882  ],\n",
       "       [ 0.6040415 ,  0.5468147 , -0.267268  , -1.079409  ,  0.03423057,\n",
       "         0.6998979 ],\n",
       "       [ 0.03382489, -1.35012   ,  0.906752  , -0.59510624,  0.5471522 ,\n",
       "        -0.20828578]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2037195e-01, 1.3457116e-01, 1.3911946e-01, 1.6004707e-01,\n",
       "        1.3926850e-01, 1.3889121e-01, 1.6773064e-01],\n",
       "       [1.2381788e-12, 4.6766243e-21, 7.8292663e-30, 9.9999988e-01,\n",
       "        5.4906926e-11, 1.5615949e-14, 1.1784184e-07],\n",
       "       [8.7862885e-01, 6.4416885e-02, 5.5617560e-02, 7.3168943e-05,\n",
       "        1.6570739e-04, 1.1577809e-04, 9.8215137e-04],\n",
       "       [4.1808707e-05, 5.1945526e-10, 9.9995816e-01, 2.2305466e-14,\n",
       "        1.5683315e-15, 4.4665339e-15, 9.8879471e-16]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actor(env.CreateObs()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xxxxxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xxxxxx\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xxxxxx' is not defined"
     ]
    }
   ],
   "source": [
    "xxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2473167"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.choose_action(env.observation_space.sample()).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xxxxxxxxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xxxxxxxxx\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xxxxxxxxx' is not defined"
     ]
    }
   ],
   "source": [
    "xxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class ActorNetwork(keras.Model):\n",
    "  def __init__(self, n_actions, fc1_dims = 64, fc2_dims = 64,\\\n",
    "    name= 'actor', chkpt_dir = 'tmp/ddpg'):\n",
    "\n",
    "    super(ActorNetwork, self).__init__()\n",
    "    self.fc1_dims = fc1_dims\n",
    "    self.fc2_dims = fc2_dims\n",
    "    self.n_actions = n_actions\n",
    "    self.model_name = name\n",
    "\n",
    "    self.checkpoint_dir = chkpt_dir\n",
    "    self.checkpoint_file = os.path.join(self.checkpoint_dir,\\\n",
    "      self.model_name +'_ddpg.h5')\n",
    "\n",
    "   \n",
    "    self.fc1 = Dense(self.fc1_dims, activation = 'relu')\n",
    "    self.fc2 = Dense(self.fc2_dims, activation = 'relu')\n",
    "    self.mu = Dense(self.n_actions, activation = 'softmax') #acao Ã© a distribuicao do ptfl\n",
    "\n",
    "  def call(self, state):\n",
    "    \n",
    "    prob = self.fc1(state)\n",
    "    prob = self.fc2(prob)\n",
    "    mu = self.mu(prob)\n",
    "\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(input_dims = env.observation_space.shape[0],\\\n",
    "   env = env, n_actions =env.action_space.shape[0])\n",
    "\n",
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "load_checkpoint = False\n",
    "\n",
    "\n",
    "if load_checkpoint:\n",
    "  n_steps = 0\n",
    "  while n_steps <= agent.batch_size:\n",
    "    observation, info = env.reset()\n",
    "    action = env.action_space.sample()\n",
    "    observation_, reward, _, done ,info = env.step(action)\n",
    "    agent.remember(observation, action, reward, observation_, done)\n",
    "    n_steps +=1\n",
    "    agent.learn()\n",
    "    agent.load_models()\n",
    "    evaluate = True\n",
    "else:\n",
    "  evaluate = False\n",
    "\n",
    "for i in range(n_games):\n",
    "  observation, info = env.reset()\n",
    "  done = False\n",
    "  score = 0\n",
    "  while not done:\n",
    "    #print(score)\n",
    "    action = agent.choose_action(observation, evaluate)\n",
    "    observation_, reward, _ ,done ,info = env.step(action)\n",
    "    score += reward\n",
    "    agent.remember(observation, action, reward, observation_, done)\n",
    "    #print(done)\n",
    "    if not load_checkpoint:\n",
    "      agent.learn()\n",
    "    observation = observation_\n",
    "  score_history.append(score)\n",
    "  avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "  if avg_score > best_score:\n",
    "    best_score = avg_score\n",
    "    if not load_checkpoint:\n",
    "      agent.save_models()\n",
    "\n",
    "  print('episode ', i, 'score %.1f' % score,'avg score %1f' % avg_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_range[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
